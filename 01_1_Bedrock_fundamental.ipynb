{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c4f52e-bd7a-4445-b2b6-dc089b4871a8",
   "metadata": {},
   "source": [
    "# 1. 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7d8622-89a8-458c-83f5-1dbee29a2e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "opensearch = boto3.client('opensearch', region)\n",
    "\n",
    "%store -r opensearch_user_id opensearch_user_password domain_name opensearch_domain_endpoint\n",
    "\n",
    "try:\n",
    "    opensearch_user_id\n",
    "    opensearch_user_password\n",
    "    domain_name\n",
    "    opensearch_domain_endpoint\n",
    "   \n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Run 00_setup notebook first or Create Your Own OpenSearch Domain\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fe8a45-35f4-4216-9c2a-5a23d10d702e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eef122-87bf-4a32-9ca0-214d473692f0",
   "metadata": {},
   "source": [
    "## Bedrock Client 생성\n",
    "### 선수 지식\n",
    "아래의 노트북을 먼저 실행해서, Bedrock 에 접근 가능하게 합니다.\n",
    "- amazon-bedrock-workshop-webinar-kr/00_Setup/setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac45651e-3db1-4e61-a0ba-2dc67652e315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n",
      "[('Titan Text Large', 'amazon.titan-tg1-large'),\n",
      " ('Titan Text Embeddings v2', 'amazon.titan-embed-g1-text-02'),\n",
      " ('Titan Text G1 - Lite', 'amazon.titan-text-lite-v1'),\n",
      " ('Titan Text G1 - Express', 'amazon.titan-text-express-v1'),\n",
      " ('Titan Embeddings G1 - Text', 'amazon.titan-embed-text-v1'),\n",
      " ('Titan Multimodal Embeddings G1', 'amazon.titan-embed-image-v1'),\n",
      " ('Titan Image Generator G1', 'amazon.titan-image-generator-v1'),\n",
      " ('SDXL 0.8', 'stability.stable-diffusion-xl'),\n",
      " ('SDXL 0.8', 'stability.stable-diffusion-xl-v0'),\n",
      " ('SDXL 1.0', 'stability.stable-diffusion-xl-v1'),\n",
      " ('J2 Grande Instruct', 'ai21.j2-grande-instruct'),\n",
      " ('J2 Jumbo Instruct', 'ai21.j2-jumbo-instruct'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid-v1'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra-v1'),\n",
      " ('Claude Instant', 'anthropic.claude-instant-v1'),\n",
      " ('Claude', 'anthropic.claude-v1'),\n",
      " ('Claude', 'anthropic.claude-v2:1'),\n",
      " ('Claude', 'anthropic.claude-v2'),\n",
      " ('Command', 'cohere.command-text-v14'),\n",
      " ('Command Light', 'cohere.command-light-text-v14'),\n",
      " ('Embed English', 'cohere.embed-english-v3'),\n",
      " ('Embed Multilingual', 'cohere.embed-multilingual-v3'),\n",
      " ('Llama 2 Chat 13B', 'meta.llama2-13b-chat-v1'),\n",
      " ('Llama 2 Chat 70B', 'meta.llama2-70b-chat-v1')]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "# os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "# print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "# pprint (bedrock_info.get_list_fm_models())\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock')\n",
    "model_list = bedrock.list_foundation_models()\n",
    "result = [(fm_list[\"modelName\"], fm_list[\"modelId\"]) for fm_list in model_list[\"modelSummaries\"] if fm_list['inferenceTypesSupported'] == ['ON_DEMAND']]\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62ce53-4a58-4b58-b36a-6f132d071f6b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `InvokeModel` body and output\n",
    "\n",
    "The `invoke_model()` method of the Amazon Bedrock runtime client (`InvokeModel` API) will be the primary method we use for most of our Text Generation and Processing tasks - whichever model we're using.\n",
    "\n",
    "Although the method is shared, the format of input and output varies depending on the foundation model used - as described below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d235b-49e1-43c3-b188-7a9371f2fc82",
   "metadata": {},
   "source": [
    "### Anthropic Claude\n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"\\n\\nHuman:<prompt>\\n\\nAnswer:\",\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"completion\": \"<output>\",\n",
    "    \"stop_reason\": \"stop_sequence\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeafe50-2cf5-482a-a88d-85f2ea3f9d54",
   "metadata": {},
   "source": [
    "### Amazon Titan Large\n",
    "\n",
    "#### Input\n",
    "```json\n",
    "{   \n",
    "    \"inputText\": \"<prompt>\",\n",
    "    \"textGenerationConfig\" : { \n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": [],\n",
    "        \"temperature\": 0.1,  \n",
    "        \"topP\": 0.9\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"inputTextTokenCount\": 613,\n",
    "    \"results\": [{\n",
    "        \"tokenCount\": 219,\n",
    "        \"outputText\": \"<output>\"\n",
    "    }]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a250461b-a062-409b-9784-6388c4ac698d",
   "metadata": {},
   "source": [
    "### AI21 Jurassic (Grande and Jumbo) \n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"<prompt>\",\n",
    "    \"maxTokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.5,\n",
    "    \"stopSequences\": [],\n",
    "    \"countPenalty\": {\"scale\": 0},\n",
    "    \"presencePenalty\": {\"scale\": 0},\n",
    "    \"frequencyPenalty\": {\"scale\": 0}\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": 1234,\n",
    "    \"prompt\": {\n",
    "        \"text\": \"<prompt>\",\n",
    "        \"tokens\": [\n",
    "            {\n",
    "                \"generatedToken\": {\n",
    "                    \"token\": \"\\u2581who\\u2581is\",\n",
    "                    \"logprob\": -12.980147361755371,\n",
    "                    \"raw_logprob\": -12.980147361755371\n",
    "                },\n",
    "                \"topTokens\": null,\n",
    "                \"textRange\": {\"start\": 0, \"end\": 6}\n",
    "            },\n",
    "            //...\n",
    "        ]\n",
    "    },\n",
    "    \"completions\": [\n",
    "        {\n",
    "            \"data\": {\n",
    "                \"text\": \"<output>\",\n",
    "                \"tokens\": [\n",
    "                    {\n",
    "                        \"generatedToken\": {\n",
    "                            \"token\": \"<|newline|>\",\n",
    "                            \"logprob\": 0.0,\n",
    "                            \"raw_logprob\": -0.01293118204921484\n",
    "                        },\n",
    "                        \"topTokens\": null,\n",
    "                        \"textRange\": {\"start\": 0, \"end\": 1}\n",
    "                    },\n",
    "                    //...\n",
    "                ]\n",
    "            },\n",
    "            \"finishReason\": {\"reason\": \"endoftext\"}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c12983-1b71-4f37-9971-837f50086b53",
   "metadata": {},
   "source": [
    "### Stability AI Stable Diffusion XL\n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"text_prompts\": [\n",
    "        {\"text\": \"this is where you place your input text\"}\n",
    "    ],\n",
    "    \"cfg_scale\": 10,\n",
    "    \"seed\": 0,\n",
    "    \"steps\": 50\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{ \n",
    "    \"result\": \"success\", \n",
    "    \"artifacts\": [\n",
    "        {\n",
    "            \"seed\": 123, \n",
    "            \"base64\": \"<image in base64>\",\n",
    "            \"finishReason\": \"SUCCESS\"\n",
    "        },\n",
    "        //...\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc8695-244e-4eff-bbe5-63aa7e069527",
   "metadata": {},
   "source": [
    "# 2. Titan Embedding 및 LLM 인 Claude-v2 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473582cc-1ae9-494c-8a08-01a0aab18c05",
   "metadata": {},
   "source": [
    "## LLM 로딩 (Claude-v2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11cce660-fc74-4ed7-b2a3-206e013fc1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "\n",
    "session = boto3.Session()\n",
    "\n",
    "retry_config = Config(\n",
    "    region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    retries={\n",
    "        \"max_attempts\": 10,\n",
    "        \"mode\": \"standard\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "bedrock_runtime = session.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    config=retry_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e3b037-1b46-466d-99e7-d31e0cca1964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_data = \"\"\"Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68e48a2-c6c0-4b38-b617-fa160310fc54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " 생명보험과 손해보험은 주로 아래와 같이 차이가 있습니다:\n",
       "\n",
       "- 생명보험의 경우 사람의 생명이나 건강에 대한 위험을 보장합니다. 즉, 피보험자가 사망하는 경우나 특정 질환이 생기는 경우 등에 지급금을 줍니다. \n",
       "\n",
       "- 손해보험은 사람이나 재산이 수배되는 손해를 보장합니다. 예를 들어 자동차보험의 경우 교통사고로 인한 자동차 수선비나 책임보험 등을 보장합니다.\n",
       "\n",
       "- 생명보험은 피보험자의 사망시나 요양비 등 지급금을 줍니다. 손해보험은 실제 발생한 손해액을 보상합니다.\n",
       "\n",
       "- 생명보험은 보험기간 동안 보험료를 지속적으로 납입해야 하지만, 손해보험은 사고 발생시 보상금을 지급합니다.\n",
       "\n",
       "이러한 점에서 생명보험은 개인의 삶과 관련한 위험을, 손해보험은 재산과 관련한 위험을 각각 보장하는 것이 주요 차이점입니다."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output, display, display_markdown, Markdown\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-instant-v1\"  # (Change this to try different model versions)\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "try:\n",
    "\n",
    "    response = bedrock_runtime.invoke_model_with_response_stream(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    stream = response.get('body')\n",
    "    output = []\n",
    "\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if chunk:\n",
    "                chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                text = chunk_obj['completion']\n",
    "                clear_output(wait=True)\n",
    "                output.append(text)\n",
    "                display_markdown(Markdown(''.join(output)))\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "\n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "\n",
    "    else:\n",
    "        raise error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7835060-ba05-4d81-82c4-1b49e97932c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b9aefe-a3f5-47f2-9a0c-a34c2cf987de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bedrock(client=<botocore.client.BedrockRuntime object at 0x7f12101984f0>, model_id='anthropic.claude-instant-v1', model_kwargs={'max_tokens_to_sample': 512}, streaming=True, callbacks=[<langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x7f11eb53ac20>])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - create the Anthropic Model\n",
    "llm_text = Bedrock(\n",
    "    model_id=modelId,\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\n",
    "        \"max_tokens_to_sample\": 512\n",
    "    },\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ac2638f-6530-4a13-9bf1-9ea263b2aeb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
    "\n",
    "<context>\n",
    "{history}\n",
    "</context>\n",
    "\n",
    "Question: {input} using within <context></context>\n",
    "\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb0501d-8677-4ca1-a0c0-48dcb41e385c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=['history', 'input']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ac1e4e-8f4e-471e-862b-a513c5baadf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "<context>\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "Assistant:\n",
      " using within <context></context>\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/llms/bedrock.py:52: UserWarning: Error: Prompt must alternate between '\n",
      "\n",
      "Human:' and '\n",
      "\n",
      "Assistant:'. Received \n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "<context>\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: \n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "Assistant:\n",
      " using within <context></context>\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "  warnings.warn(ALTERNATION_ERROR + f\" Received {input_text}\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/llms/bedrock.py:57: UserWarning: Error: Prompt must alternate between '\n",
      "\n",
      "Human:' and '\n",
      "\n",
      "Assistant:'. Received \n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "<context>\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: \n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "Assistant:\n",
      " using within <context></context>\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "  warnings.warn(ALTERNATION_ERROR + f\" Received {input_text}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 생명 보험과 손해 보험의 주요한 차이점은 아래와 같습니다:\n",
      "\n",
      "- 생명 보험은 보험 가입자의 사망시 사망보장금을 지급합니다. 즉, 생명 보험은 개인의 생명을 대상으로 합니다. \n",
      "\n",
      "- 손해 보험은 사고로 인한 재산 손실이나 배상책임을 보상합니다. 예를 들어 자동차 손해 보험은 교통사고로 발생한 자동차 수리비용을, 화재 손해 보험은 화재로 인한 건조물의 손실을 각각 보상합니다.\n",
      "\n",
      "- 생명 보험은 보험 기간 동안 보험 가입자가 살아있을 동안 보험 사고가 발생하지 않는 이상 보상금을 지급하지 않습니다. 손해 보험은 보험 사고가 발생했을 경우 보상금을 지급합니다.\n",
      "\n",
      "- 생명 보험은 개인 생명을, 손해 보험은 재산을 대상으로 하므로 가입 목적이 다릅니다.\n",
      "\n",
      "이상이 생명 보험과 손해 보험의 주요 차이점입니다. 도움이 되었기를 바랍니다.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 생명 보험과 손해 보험의 주요한 차이점은 아래와 같습니다:\\n\\n- 생명 보험은 보험 가입자의 사망시 사망보장금을 지급합니다. 즉, 생명 보험은 개인의 생명을 대상으로 합니다. \\n\\n- 손해 보험은 사고로 인한 재산 손실이나 배상책임을 보상합니다. 예를 들어 자동차 손해 보험은 교통사고로 발생한 자동차 수리비용을, 화재 손해 보험은 화재로 인한 건조물의 손실을 각각 보상합니다.\\n\\n- 생명 보험은 보험 기간 동안 보험 가입자가 살아있을 동안 보험 사고가 발생하지 않는 이상 보상금을 지급하지 않습니다. 손해 보험은 보험 사고가 발생했을 경우 보상금을 지급합니다.\\n\\n- 생명 보험은 개인 생명을, 손해 보험은 재산을 대상으로 하므로 가입 목적이 다릅니다.\\n\\n이상이 생명 보험과 손해 보험의 주요 차이점입니다. 도움이 되었기를 바랍니다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm_text, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory(),\n",
    "    prompt=PROMPT\n",
    ")\n",
    "\n",
    "conversation.predict(input=prompt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a54604-0e90-4d2a-8eda-d02c048d8a01",
   "metadata": {},
   "source": [
    "## Function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f642d74-226b-4532-99fd-015889de3dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.function_call import add_tools, run_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "114342ea-343a-48a3-86c2-29f49f4bc310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompt(tools_string, user_input):\n",
    "    prompt_template = f\"\"\"\n",
    "In this environment you have access to a set of tools you can use to answer the user's question.\n",
    "\n",
    "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
    "<function_calls>\n",
    "<invoke>\n",
    "<tool_name>$TOOL_NAME</tool_name>\n",
    "<parameters>\n",
    "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
    "...\n",
    "</parameters>\n",
    "</invoke>\n",
    "</function_calls>\n",
    "\n",
    "Here are the tools available:\n",
    "<tools>\n",
    "{tools_string}\n",
    "</tools>\n",
    "\n",
    "Human:\n",
    "{user_input}\n",
    "\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ff32cb2-ab11-44a1-932a-22a80ea5bc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this environment you have access to a set of tools you can use to answer the user's question.\n",
      "\n",
      "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>$TOOL_NAME</tool_name>\n",
      "<parameters>\n",
      "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
      "...\n",
      "</parameters>\n",
      "</invoke>\n",
      "</function_calls>\n",
      "\n",
      "Here are the tools available:\n",
      "<tools>\n",
      "\n",
      "            <tool_description>\n",
      "            <tool_name>get_weather</tool_name>\n",
      "            <description>\n",
      "            Returns weather data for a given latitude and longitude. </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>latitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The latitude coordinate as a string</description>\n",
      "            </parameter> <parameter>\n",
      "            <name>longitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The longitude coordinate as a string</description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "            <tool_description>\n",
      "            <tool_name>get_lat_long</tool_name>\n",
      "            <description>\n",
      "            Returns the latitude and longitude for a given place name.\n",
      "            </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>place</name>  \n",
      "            <type>string</type>\n",
      "            <description>\n",
      "            The place name to geocode and get coordinates for.\n",
      "            </description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "</tools>\n",
      "\n",
      "Human:\n",
      "Can you check the weather for me in Paris, France?\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_lat_long</tool_name>\n",
      "                        <stdout>{'latitude': '48.8534951', 'longitude': '2.3483915'}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_weather</tool_name>\n",
      "                        <stdout>{'latitude': 48.86, 'longitude': 2.3399997, 'generationtime_ms': 0.053048133850097656, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 43.0, 'current_weather_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature': '°C', 'windspeed': 'km/h', 'winddirection': '°', 'is_day': '', 'weathercode': 'wmo code'}, 'current_weather': {'time': '2024-01-15T05:15', 'interval': 900, 'temperature': 0.7, 'windspeed': 5.9, 'winddirection': 256, 'is_day': 0, 'weathercode': 71}}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "\n",
      "\n",
      "The get_weather tool returned the current weather data for the latitude and longitude of Paris. It is currently 0.7°C with 5.9 km/h winds from the WSW. The weather code 71 corresponds to \"Light snow\".\n",
      "\n",
      "So in summary, it is currently lightly snowing in Paris with a temperature just below freezing. Let me know if you need any other weather details!\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you check the weather for me in Paris, France?\"\n",
    "tools_string = add_tools()\n",
    "prompt = create_prompt(tools_string, user_input)\n",
    "run_loop(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f221ad1a-54c2-4ce4-8810-f9737dad0732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this environment you have access to a set of tools you can use to answer the user's question.\n",
      "\n",
      "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>$TOOL_NAME</tool_name>\n",
      "<parameters>\n",
      "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
      "...\n",
      "</parameters>\n",
      "</invoke>\n",
      "</function_calls>\n",
      "\n",
      "Here are the tools available:\n",
      "<tools>\n",
      "\n",
      "            <tool_description>\n",
      "            <tool_name>get_weather</tool_name>\n",
      "            <description>\n",
      "            Returns weather data for a given latitude and longitude. </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>latitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The latitude coordinate as a string</description>\n",
      "            </parameter> <parameter>\n",
      "            <name>longitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The longitude coordinate as a string</description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "            <tool_description>\n",
      "            <tool_name>get_lat_long</tool_name>\n",
      "            <description>\n",
      "            Returns the latitude and longitude for a given place name.\n",
      "            </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>place</name>  \n",
      "            <type>string</type>\n",
      "            <description>\n",
      "            The place name to geocode and get coordinates for.\n",
      "            </description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "</tools>\n",
      "\n",
      "Human:\n",
      "한국의 오늘 날씨는 어떻게 되나요?\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_lat_long</tool_name>\n",
      "                        <stdout>{'latitude': '36.638392', 'longitude': '127.6961188'}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_weather</tool_name>\n",
      "                        <stdout>{'latitude': 36.65, 'longitude': 127.6875, 'generationtime_ms': 0.06496906280517578, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 342.0, 'current_weather_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature': '°C', 'windspeed': 'km/h', 'winddirection': '°', 'is_day': '', 'weathercode': 'wmo code'}, 'current_weather': {'time': '2024-01-15T05:15', 'interval': 900, 'temperature': -0.9, 'windspeed': 13.0, 'winddirection': 312, 'is_day': 1, 'weathercode': 0}}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "\n",
      "\n",
      "한국의 현재 기온은 -0.9도이고, 풍속은 시속 13km입니다. 날씨는 맑은 것 같습니다.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"한국의 오늘 날씨는 어떻게 되나요?\"\n",
    "tools_string = add_tools()\n",
    "prompt = create_prompt(tools_string, user_input)\n",
    "run_loop(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d10308-062c-4f8e-91b9-af5f64cea88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
